{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5d4529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T01:24:43.863921Z",
     "start_time": "2023-07-03T01:24:43.855526Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af88c9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T19:05:22.088388Z",
     "start_time": "2023-07-06T19:04:52.402681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:04:52.491617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 21:04:54.533370: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:04:54.533502: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-06 21:05:04.196949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:05:04.197322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:05:04.197350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# misc\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# load/save files\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# datascience libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "try: # python\n",
    "    path_ = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"..\")\n",
    "except NameError: # jupyter notebook\n",
    "    path_ = os.path.dirname(os.getcwd())\n",
    "\n",
    "dataset_dir = os.path.join(path_, \"datasets\")\n",
    "model_dir = os.path.join(path_, \"models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8f58d",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478508f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T19:03:48.735308Z",
     "start_time": "2023-07-06T19:03:48.703818Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sys import argv\n",
    "\n",
    "def _time(f):\n",
    "    def wrapper(*args):\n",
    "        start = time()\n",
    "        r = f(*args)\n",
    "        end = time()\n",
    "        print(\"%s(): timed %fs\" % (f.__name__, end-start))\n",
    "        return r\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6504048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T01:24:23.889709Z",
     "start_time": "2023-07-03T01:24:23.880291Z"
    }
   },
   "source": [
    "# Load exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37121241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T19:47:12.789483Z",
     "start_time": "2023-07-06T19:47:12.734254Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from types import SimpleNamespace as Namespace\n",
    "except ImportError:\n",
    "    from argparse import Namespace\n",
    "\n",
    "@_time\n",
    "def emnist_load_data(dir_path:str, return_mapping=False):\n",
    "    # https://towardsdatascience.com/efficiently-splitting-an-image-into-tiles-in-python-using-numpy-d1bf0dd7b6f7\n",
    "    def array_to_tiled_array(img:np.ndarray, kernel_size:tuple):\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        img_height, img_width, channels = img.shape\n",
    "        tile_height, tile_width = kernel_size\n",
    "        tiles = img.reshape(img_height // tile_height,\n",
    "                            tile_height,\n",
    "                            img_width // tile_width,\n",
    "                            tile_width,\n",
    "                            channels)\n",
    "        return tiles.swapaxes(1,2).reshape(-1, tile_height,tile_width, 1)\n",
    "\n",
    "    def load_data_X(path:str):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            obj = json.loads(f.read(), object_hook = lambda d: Namespace(**d))\n",
    "        X = np.zeros((0, 28,28,1), dtype=\"uint8\")\n",
    "        for s in obj.files:\n",
    "            img_path = os.path.join(os.path.dirname(path), s)\n",
    "            im = Image.open(img_path).convert('L')\n",
    "            data = array_to_tiled_array(np.array(im,dtype=\"uint8\"), (28,28))\n",
    "            X = np.append(X, data, axis=0)\n",
    "        return X\n",
    "\n",
    "    def load_data_y(path:str):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            obj = json.loads(f.read(), object_hook = lambda d: Namespace(**d))\n",
    "        return [np.array(obj.id, dtype=\"uint8\"),\n",
    "                np.array(obj.bbox, dtype=\"uint8\")], np.array(obj.mapping, dtype=\"uint8\")\n",
    "    \n",
    "    path = os.path.join(dir_path, \"test.json\")\n",
    "    X_test = load_data_X(path)\n",
    "    y_test, y_mapping = load_data_y(path)\n",
    "    path = os.path.join(dir_path, \"train.json\")\n",
    "    X_train = load_data_X(path)\n",
    "    y_train, y_mapping = load_data_y(path)\n",
    "    if return_mapping:\n",
    "        return (X_train, y_train), (X_test, y_test),  list(map(lambda x: chr(x), y_mapping))\n",
    "    else:\n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bfa12",
   "metadata": {},
   "source": [
    "# Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4ef233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T19:06:18.421013Z",
     "start_time": "2023-07-06T19:06:18.403719Z"
    }
   },
   "outputs": [],
   "source": [
    "# datascience libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tensorflow\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from keras import datasets\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.backend import expand_dims\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aac190d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T20:07:00.074699Z",
     "start_time": "2023-07-06T20:06:59.974666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emnist_load_data(): timed 0.039964s\n",
      "\n",
      "X_train: (150, 28, 28, 1)\n",
      "y_train_id: (150, 10)\n",
      "y_train_bbox: (150, 4)\n",
      "\n",
      "X_val: (51, 28, 28, 1)\n",
      "y_val_id: (51, 10)\n",
      "y_val_bbox: (51, 4)\n",
      "\n",
      "X_test: (201, 28, 28, 1)\n",
      "y_test_id: (201, 10)\n",
      "y_test_bbox: (201, 4)\n",
      "\n",
      "Mapping:\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "#(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(X_train, y_train), (X_test, y_test), y_mapping = emnist_load_data(os.path.join(dataset_dir, \"origin-emnist-mnist\"), True)\n",
    "\n",
    "# convert target[0] to categorical\n",
    "num_classes = max(y_train[0])+1 # len(y_mapping)\n",
    "y_train[0] = to_categorical(y_train[0], num_classes=num_classes, dtype =\"int8\")\n",
    "y_test[0] = to_categorical(y_test[0], num_classes=num_classes, dtype =\"int8\")\n",
    "\n",
    "# add validation sets\n",
    "y_val = [None,None]\n",
    "(X_train, X_val) = train_test_split(X_train, test_size=0.25, random_state=1)\n",
    "(y_train[0], y_val[0]) = train_test_split(y_train[0], test_size=0.25, random_state=1)\n",
    "(y_train[1], y_val[1]) = train_test_split(y_train[1], test_size=0.25, random_state=1)\n",
    "\n",
    "print(\"\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train_id:\", y_train[0].shape)\n",
    "print(\"y_train_bbox:\", y_train[1].shape)\n",
    "print(\"\")\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val_id:\", y_val[0].shape)\n",
    "print(\"y_val_bbox:\", y_val[1].shape)\n",
    "print(\"\")\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test_id:\", y_test[0].shape)\n",
    "print(\"y_test_bbox:\", y_test[1].shape)\n",
    "print(\"\\nMapping:\")\n",
    "print(y_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a4971c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T19:06:32.489680Z",
     "start_time": "2023-07-06T19:06:32.444473Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def set_model(X):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, kernel_size=(5, 5),\n",
    "                            activation='relu', padding='same', input_shape = X[0].shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(strides=(2,2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(strides=(2,2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1316860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T19:06:36.750307Z",
     "start_time": "2023-07-06T19:06:34.837316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:06:34.924572: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:06:34.929894: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-06 21:06:34.929999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-DIV5ILM): /proc/driver/nvidia/version does not exist\n",
      "2023-07-06 21:06:34.943377: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        25632     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 10, 10, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1639424   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,781,930\n",
      "Trainable params: 2,781,546\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = set_model(X_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a03d438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T19:06:46.037089Z",
     "start_time": "2023-07-06T19:06:45.950221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nes/.pyenv/versions/3.8.12/envs/BatteryProject/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizers.Adam(lr=0.0001),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31aafe65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T00:19:51.662585Z",
     "start_time": "2023-07-04T00:19:51.527031Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m                              validation_data=(X_val, Y_val)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m                              steps_per_epoch=1000,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m                              epochs=25,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m                              verbose=1)\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m()\n\u001b[1;32m      7\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train,\n\u001b[1;32m      8\u001b[0m                     validation_data \u001b[38;5;241m=\u001b[39m (X_val, y_val),\n\u001b[1;32m      9\u001b[0m                     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     10\u001b[0m                     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     11\u001b[0m                     callbacks \u001b[38;5;241m=\u001b[39m callbacks,\n\u001b[1;32m     12\u001b[0m                     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m training_time \u001b[38;5;241m=\u001b[39m timer() \u001b[38;5;241m-\u001b[39m start_time\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timer' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                              validation_data=(X_val, Y_val)\n",
    "                              steps_per_epoch=1000,\n",
    "                              epochs=25,\n",
    "                              verbose=1)\"\"\"\n",
    "callbacks = []\n",
    "es = EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "callbacks.append(es)\n",
    "\n",
    "start_time = timer()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    batch_size = 32,\n",
    "                    epochs = 3,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1)\n",
    "training_time = timer() - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
